{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TI'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLOG_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_codes = ['NV', 'DM', 'TI', 'EG', 'BR']\n",
    "\n",
    "codes = [bc for bc in blog_codes if bc in full_path]\n",
    "blog_code = codes[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TI'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path = 'C:/projects/A3rcs/repository/blog_post/2019/TI/by_id/20191128/s1_0314625.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/projects/A3rcs/repository/blog_post/2019/TI/by_id/20191128/s1_0314625.csv\n"
     ]
    }
   ],
   "source": [
    "generate_ti_crawler(id_list, start_date=20191101, end_date=20191128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.s1_collect.blog.bl_ti import ti_blog_post_crawler as ti_crawler\n",
    "from module.s1_collect.comm import util\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "BLOG_NAME   = \"TISTORY\"\n",
    "BLOG_CODE   = util.get_blog_code(BLOG_NAME)\n",
    "dates       = datetime.datetime.now()\n",
    "\n",
    "root_dir    = util.get_root_dir()\n",
    "file_dir    = util.get_file_dir()\n",
    "\n",
    "id_path     = root_dir + util.get_user_dir(file_dir)\n",
    "rep_dir     = root_dir + util.get_pblog_id_dir(file_dir)\n",
    "folder_path = '/'.join(rep_dir.split('/')[:-1]).format(yyyy=dates.year, blog_code=BLOG_CODE,\n",
    "                                                       yyyymmdd=dates.strftime('%Y%m%d'))\n",
    "\n",
    "id_list = pd.read_csv(id_path+'TI_ID_List.csv', engine='python', encoding = 'utf-8')\n",
    "id_list = id_list.to_dict(orient='record')\n",
    "\n",
    "\n",
    "def generate_ti_crawler(id_list, start_date, end_date):\n",
    "    try :\n",
    "        for user_info in id_list[:3]:\n",
    "            full_path = rep_dir.format(yyyy=dates.year, blog_code=BLOG_CODE, yyyymmdd=dates.strftime('%Y%m%d'),\n",
    "                                       user_id=user_info['user_id'])\n",
    "            print(full_path)\n",
    "\n",
    "            blog_url = ti_crawler.get_blog_url(user_info['user_id'])\n",
    "            all_content_info = ti_crawler.gather_all_content(blog_url, start_date, end_date,\n",
    "                                                             newest_post_num=user_info['newest_post_num'],  oldest_post_num=1)\n",
    "            chk_succ = ti_crawler.make_blog_DF(all_content_info, user_info['user_id'], full_path)\n",
    "\n",
    "        is_success = True\n",
    "\n",
    "    except Exception as e :\n",
    "        print(BLOG_NAME, e)\n",
    "        is_success = False\n",
    "    return is_success\n",
    "\n",
    "\n",
    "\n",
    "def concat_post_date(folder_path):\n",
    "    try:\n",
    "        csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "        dataframes = []\n",
    "\n",
    "        for csv_file in csv_files :\n",
    "            df = pd.read_csv(csv_file)\n",
    "            dataframes.append(df)\n",
    "\n",
    "        result = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "        pblog_date_path = root_dir+util.get_pblog_date_dir(file_dir).format(yyyy=dates.year, blog_code=BLOG_CODE,\n",
    "                                                                            yyyymmdd=dates.strftime('%Y%m%d'))\n",
    "\n",
    "        util.save_df2csv(result, pblog_date_path)\n",
    "        is_success = True\n",
    "\n",
    "    except Exception as e :\n",
    "        print(BLOG_NAME, e)\n",
    "        is_success = False\n",
    "    return is_success\n",
    "\n",
    "\n",
    "# try :\n",
    "#     generate_ti_crawler(id_list, start_date=20191101, end_date=20191128)\n",
    "#     concat_post_date(folder_path)\n",
    "#     print('TI blog post Crawler is done..')\n",
    "\n",
    "# except Exception as e :\n",
    "#     error_type = str(e.with_traceback).split(' ')[4]\n",
    "#     util.make_error_log_message(error_type, BLOG_CODE.upper())\n",
    "#     print('Error! Check TI log_massage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
